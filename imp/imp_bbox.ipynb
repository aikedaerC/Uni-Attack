{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# my_label_path=\"/home/aikedaer/mydata/data/lingodt/val.csv\"\n","# my_image_path=\"/home/aikedaer/mydata/data/lingodt\"\n","\n","# my_label_path=\"/home/aikedaer/mydata/data/comp/question1.csv\"\n","# my_image_path=\"/home/aikedaer/mydata/data/comp\"\n","# qton = \"question1\"\n","type_method = \"sga_albef\"\n","my_label_path=\"/home/aikedaer/mydata/data/comp/question2.csv\"\n","my_image_path=f\"/home/aikedaer/mydata/data/comp/attacked/phase2/{type_method}\"\n","qton = \"question2\" "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# !pip install transformers==v4.39.2\n","# !pip install -q pillow acceleratea einops\n","# export CUDA_VISIBLE_DEVICES=1"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: transformers\n","Version: 4.39.2\n","Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n","Home-page: https://github.com/huggingface/transformers\n","Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n","Author-email: transformers@huggingface.co\n","License: Apache 2.0 License\n","Location: /mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages\n","Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n","Required-by: transformers-stream-generator\n"]}],"source":["!pip show transformers"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"data":{"text/plain":["'2.3.0+cu121'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from PIL import Image\n","# torch.set_default_device(\"cuda\")\n","default_device = torch.device(\"cuda:0\")\n","torch.cuda.set_device(default_device)\n","torch.__version__\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# !git clone https://huggingface.co/MILVLG/imp-v1-3b"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# !huggingface-cli download --resume-download MILVLG/imp-v1-3b"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"ename":"RuntimeError","evalue":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# os.environ['HF_ENDPOINT'] = 'hf-mirror.com'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMILVLG/imp-v1-3b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# force_download=True,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMILVLG/imp-v1-3b\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n","File \u001b[0;32m/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/transformers/modeling_utils.py:3463\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   3459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has some weights that should be kept in higher precision, you need to upgrade \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`accelerate` to properly deal with them (`pip install --upgrade accelerate`).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3461\u001b[0m     )\n\u001b[1;32m   3462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 3463\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_balanced_memory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced_low_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3471\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m get_max_memory(max_memory)\n","File \u001b[0;32m/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/accelerate/utils/modeling.py:957\u001b[0m, in \u001b[0;36mget_balanced_memory\u001b[0;34m(model, max_memory, no_split_module_classes, dtype, special_dtypes, low_zero)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# Get default / clean up max_memory\u001b[39;00m\n\u001b[1;32m    956\u001b[0m user_not_set_max_memory \u001b[38;5;241m=\u001b[39m max_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 957\u001b[0m max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n\u001b[1;32m    960\u001b[0m     num_devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m max_memory \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(d)\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m max_memory[d] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m/mnt/data1/aikedaer/anaconda3/envs/imp/lib/python3.10/site-packages/accelerate/utils/modeling.py:825\u001b[0m, in \u001b[0;36mget_max_memory\u001b[0;34m(max_memory)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()):\n\u001b[0;32m--> 825\u001b[0m             _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m         max_memory \u001b[38;5;241m=\u001b[39m {i: torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmem_get_info(i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())}\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# allocate everything in the mps device as the RAM is shared\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["#Create model\n","# import os\n","# os.environ['HF_ENDPOINT'] = 'hf-mirror.com'\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"MILVLG/imp-v1-3b\", \n","    torch_dtype=torch.float16, \n","    device_map=\"auto\",\n","    trust_remote_code=True,\n","    # force_download=True,\n","    resume_download=True)\n","tokenizer = AutoTokenizer.from_pretrained(\"MILVLG/imp-v1-3b\", trust_remote_code=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install pyarrow fastparquet -i https://pypi.tuna.tsinghua.edu.cn/simple"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install pandas -i https://pypi.tuna.tsinghua.edu.cn/simple"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 922/922 [1:53:34<00:00,  7.39s/it]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_id</th>\n","      <th>segment_id</th>\n","      <th>answer</th>\n","      <th>question</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>xxxxxxxxxxx_0</td>\n","      <td>xxxxxxxxxxxxx_0</td>\n","      <td>In the image, there are no cars, traffic light...</td>\n","      <td>how many cars, traffic lights, road signals, p...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>xxxxxxxxxxx_1</td>\n","      <td>xxxxxxxxxxxxx_1</td>\n","      <td>The cars in the image are black, the traffic l...</td>\n","      <td>what colors are the cars, traffic lights, road...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>xxxxxxxxxxx_2</td>\n","      <td>xxxxxxxxxxxxx_2</td>\n","      <td>There is one car, one traffic light, one road ...</td>\n","      <td>how many cars, traffic lights, road signals, p...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>xxxxxxxxxxx_3</td>\n","      <td>xxxxxxxxxxxxx_3</td>\n","      <td>The cars in the image are red, the traffic lig...</td>\n","      <td>what colors are the cars, traffic lights, road...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>xxxxxxxxxxx_4</td>\n","      <td>xxxxxxxxxxxxx_4</td>\n","      <td>In the image, there is one car, two traffic li...</td>\n","      <td>how many cars, traffic lights, road signals, p...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>917</th>\n","      <td>xxxxxxxxxxx_917</td>\n","      <td>xxxxxxxxxxxxx_917</td>\n","      <td>The cars in the image are black, the traffic l...</td>\n","      <td>what colors are the cars, traffic lights, road...</td>\n","    </tr>\n","    <tr>\n","      <th>918</th>\n","      <td>xxxxxxxxxxx_918</td>\n","      <td>xxxxxxxxxxxxx_918</td>\n","      <td>The image does not show any cars, traffic ligh...</td>\n","      <td>how many cars, traffic lights, road signals, p...</td>\n","    </tr>\n","    <tr>\n","      <th>919</th>\n","      <td>xxxxxxxxxxx_919</td>\n","      <td>xxxxxxxxxxxxx_919</td>\n","      <td>The cars in the image are black, the traffic l...</td>\n","      <td>what colors are the cars, traffic lights, road...</td>\n","    </tr>\n","    <tr>\n","      <th>920</th>\n","      <td>xxxxxxxxxxx_920</td>\n","      <td>xxxxxxxxxxxxx_920</td>\n","      <td>In the image, there are no cars, traffic light...</td>\n","      <td>how many cars, traffic lights, road signals, p...</td>\n","    </tr>\n","    <tr>\n","      <th>921</th>\n","      <td>xxxxxxxxxxx_921</td>\n","      <td>xxxxxxxxxxxxx_921</td>\n","      <td>The cars in the image are white, the traffic l...</td>\n","      <td>what colors are the cars, traffic lights, road...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>922 rows × 4 columns</p>\n","</div>"],"text/plain":["         question_id         segment_id  \\\n","0      xxxxxxxxxxx_0    xxxxxxxxxxxxx_0   \n","1      xxxxxxxxxxx_1    xxxxxxxxxxxxx_1   \n","2      xxxxxxxxxxx_2    xxxxxxxxxxxxx_2   \n","3      xxxxxxxxxxx_3    xxxxxxxxxxxxx_3   \n","4      xxxxxxxxxxx_4    xxxxxxxxxxxxx_4   \n","..               ...                ...   \n","917  xxxxxxxxxxx_917  xxxxxxxxxxxxx_917   \n","918  xxxxxxxxxxx_918  xxxxxxxxxxxxx_918   \n","919  xxxxxxxxxxx_919  xxxxxxxxxxxxx_919   \n","920  xxxxxxxxxxx_920  xxxxxxxxxxxxx_920   \n","921  xxxxxxxxxxx_921  xxxxxxxxxxxxx_921   \n","\n","                                                answer  \\\n","0    In the image, there are no cars, traffic light...   \n","1    The cars in the image are black, the traffic l...   \n","2    There is one car, one traffic light, one road ...   \n","3    The cars in the image are red, the traffic lig...   \n","4    In the image, there is one car, two traffic li...   \n","..                                                 ...   \n","917  The cars in the image are black, the traffic l...   \n","918  The image does not show any cars, traffic ligh...   \n","919  The cars in the image are black, the traffic l...   \n","920  In the image, there are no cars, traffic light...   \n","921  The cars in the image are white, the traffic l...   \n","\n","                                              question  \n","0    how many cars, traffic lights, road signals, p...  \n","1    what colors are the cars, traffic lights, road...  \n","2    how many cars, traffic lights, road signals, p...  \n","3    what colors are the cars, traffic lights, road...  \n","4    how many cars, traffic lights, road signals, p...  \n","..                                                 ...  \n","917  what colors are the cars, traffic lights, road...  \n","918  how many cars, traffic lights, road signals, p...  \n","919  what colors are the cars, traffic lights, road...  \n","920  how many cars, traffic lights, road signals, p...  \n","921  what colors are the cars, traffic lights, road...  \n","\n","[922 rows x 4 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import os\n","from tqdm import tqdm \n","\n","def get_answer(img_path, question):\n","    text = f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. \\\n","            USER: <image>\\n{question} ASSISTANT:\"\n","    file_pth = os.path.join(my_image_path,img_path)\n","    image0 = Image.open(file_pth) \n","    input_ids = tokenizer(text, return_tensors='pt').input_ids.to(default_device)\n","    image_tensor0 = model.image_preprocess(image0).to(default_device)\n","\n","    #Generate the answer\n","    output_ids = model.generate(\n","        input_ids,\n","        max_new_tokens=50,\n","        images=image_tensor0,\n","        use_cache=True)[0]\n","    asw = tokenizer.decode(output_ids[input_ids.shape[1]:], skip_special_tokens=True).strip()\n","\n","    return asw\n","def str2list(input_string):\n","    # Remove the brackets and split by newline character\n","    list_elements = input_string.strip(\"[]\").split('\\n')\n","\n","    # Remove any extra spaces and quotes\n","    cleaned_list = [element.strip(\" '\") for element in list_elements]\n","    return cleaned_list\n","\n","val = pd.read_csv(my_label_path)\n","val[\"images\"] = val[\"images\"].map(str2list)\n","predictions = pd.DataFrame(columns=[\"question_id\", \"segment_id\", \"answer\"])\n","\n","for index, row in tqdm(val.iterrows(), total=val.shape[0]):\n","    question_id = row['question_id']\n","    segment_id = row['segment_id']\n","    images = row['images']\n","    question = row['question']\n","    answer = row['answer']\n","    # only use the first frame\n","    asw = get_answer(images[0], question)\n","    # Create a DataFrame for the current row\n","    new_row = pd.DataFrame({\n","        \"question_id\": [question_id],\n","        \"segment_id\": [segment_id],\n","        \"question\": [question],\n","        \"answer\": [asw]\n","    })\n","\n","    # Append the new row to the predictions DataFrame using pd.concat\n","    predictions = pd.concat([predictions, new_row], ignore_index=True)\n","    # break\n","\n","predictions\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["my_new = f\"/home/aikedaer/mydata/data/comp/predict/{type_method}/{qton}_imp_predict.csv\"\n","predictions.to_csv(my_new)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}
