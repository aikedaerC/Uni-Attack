{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_label_path=\"/home/aikedaer/mydata/data/lingodt/val.csv\"\n",
    "# my_image_path=\"/home/aikedaer/mydata/data/lingodt\"\n",
    "\n",
    "# my_label_path=\"/home/aikedaer/mydata/data/comp/question1.csv\"\n",
    "# my_image_path=\"/home/aikedaer/mydata/data/comp\"\n",
    "# qton = \"question1\"\n",
    "\n",
    "my_label_path=\"/home/aikedaer/mydata/data/comp/question2.csv\"\n",
    "my_image_path=\"/home/aikedaer/mydata/data/comp/images/phase2\"\n",
    "qton = \"question2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/aikedaer/anaconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/data1/aikedaer/anaconda3/envs/llava/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/mnt/data1/aikedaer/anaconda3/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "import os\n",
    "# os.environ['HF_ENDPOINT'] = 'hf-mirror.com'\n",
    "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "model_name=get_model_name_from_path(model_path)\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=model_name,\n",
    "    load_4bit=True,\n",
    "    device_map=\"cuda:3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llava.constants import (\n",
    "    IMAGE_TOKEN_INDEX,\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    DEFAULT_IM_START_TOKEN,\n",
    "    DEFAULT_IM_END_TOKEN,\n",
    "    IMAGE_PLACEHOLDER,\n",
    ")\n",
    "from llava.conversation import conv_templates\n",
    "import re\n",
    "from PIL import Image\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from llava.mm_utils import (\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    "    get_model_name_from_path,\n",
    ")\n",
    "import torch\n",
    "\n",
    "def image_parser(image_file):\n",
    "    out = image_file.split(\",\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_image(image_file):\n",
    "    if image_file.startswith(\"http\") or image_file.startswith(\"https\"):\n",
    "        response = requests.get(image_file)\n",
    "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    else:\n",
    "        image = Image.open(image_file).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_images(image_files):\n",
    "    out = []\n",
    "    for image_file in image_files:\n",
    "        image = load_image(image_file)\n",
    "        out.append(image)\n",
    "    return out\n",
    "\n",
    "\n",
    "def chat(qs, image_file):\n",
    "    # qs = \"what color is the car?\"\n",
    "    # image_file = \"\"\n",
    "\n",
    "    temperature = 0\n",
    "    top_p = None\n",
    "    num_beams = 1\n",
    "    max_new_tokens = 100\n",
    "\n",
    "    image_token_se = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN\n",
    "    if IMAGE_PLACEHOLDER in qs:\n",
    "        if model.config.mm_use_im_start_end:\n",
    "            qs = re.sub(IMAGE_PLACEHOLDER, image_token_se, qs)\n",
    "        else:\n",
    "            qs = re.sub(IMAGE_PLACEHOLDER, DEFAULT_IMAGE_TOKEN, qs)\n",
    "    else:\n",
    "        if model.config.mm_use_im_start_end:\n",
    "            qs = image_token_se + \"\\n\" + qs\n",
    "        else:\n",
    "            qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "\n",
    "    if \"llama-2\" in model_name.lower():\n",
    "        conv_mode = \"llava_llama_2\"\n",
    "    elif \"mistral\" in model_name.lower():\n",
    "        conv_mode = \"mistral_instruct\"\n",
    "    elif \"v1.6-34b\" in model_name.lower():\n",
    "        conv_mode = \"chatml_direct\"\n",
    "    elif \"v1\" in model_name.lower():\n",
    "        conv_mode = \"llava_v1\"\n",
    "    elif \"mpt\" in model_name.lower():\n",
    "        conv_mode = \"mpt\"\n",
    "    else:\n",
    "        conv_mode = \"llava_v0\"\n",
    "\n",
    "    conv = conv_templates[conv_mode].copy()\n",
    "    conv.append_message(conv.roles[0], qs)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "\n",
    "    image_files = image_parser(image_file)\n",
    "    images = load_images(image_files)\n",
    "    image_sizes = [x.size for x in images]\n",
    "    images_tensor = process_images(\n",
    "        images,\n",
    "        image_processor,\n",
    "        model.config\n",
    "    ).to(model.device, dtype=torch.float16)\n",
    "\n",
    "    input_ids = (\n",
    "        tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\")\n",
    "        .unsqueeze(0)\n",
    "        .cuda()\n",
    "    )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            images=images_tensor,\n",
    "            image_sizes=image_sizes,\n",
    "            do_sample=True if temperature > 0 else False,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            num_beams=num_beams,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/922 [00:00<?, ?it/s]/mnt/data1/aikedaer/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/mnt/data1/aikedaer/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 922/922 [27:55<00:00,  1.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxxxxxxxxxx_0</td>\n",
       "      <td>xxxxxxxxxxxxx_0</td>\n",
       "      <td>In the image, there are several cars, traffic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxxxxxxxxxx_1</td>\n",
       "      <td>xxxxxxxxxxxxx_1</td>\n",
       "      <td>In the image, the cars are black, the traffic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxxxxxxxxxx_2</td>\n",
       "      <td>xxxxxxxxxxxxx_2</td>\n",
       "      <td>In the image, there are two cars, two traffic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxxxxxxxxxx_3</td>\n",
       "      <td>xxxxxxxxxxxxx_3</td>\n",
       "      <td>The cars in the image are red, the traffic lig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxxxxxxxxxx_4</td>\n",
       "      <td>xxxxxxxxxxxxx_4</td>\n",
       "      <td>In the image, there are several cars, traffic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>xxxxxxxxxxx_917</td>\n",
       "      <td>xxxxxxxxxxxxx_917</td>\n",
       "      <td>The cars in the image are black, the traffic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>xxxxxxxxxxx_918</td>\n",
       "      <td>xxxxxxxxxxxxx_918</td>\n",
       "      <td>In the image, there are no cars, traffic light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>xxxxxxxxxxx_919</td>\n",
       "      <td>xxxxxxxxxxxxx_919</td>\n",
       "      <td>The cars in the image are white, the traffic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>xxxxxxxxxxx_920</td>\n",
       "      <td>xxxxxxxxxxxxx_920</td>\n",
       "      <td>In the image, there are no cars, traffic light...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>xxxxxxxxxxx_921</td>\n",
       "      <td>xxxxxxxxxxxxx_921</td>\n",
       "      <td>The cars in the image are white, the traffic l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>922 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         question_id         segment_id  \\\n",
       "0      xxxxxxxxxxx_0    xxxxxxxxxxxxx_0   \n",
       "1      xxxxxxxxxxx_1    xxxxxxxxxxxxx_1   \n",
       "2      xxxxxxxxxxx_2    xxxxxxxxxxxxx_2   \n",
       "3      xxxxxxxxxxx_3    xxxxxxxxxxxxx_3   \n",
       "4      xxxxxxxxxxx_4    xxxxxxxxxxxxx_4   \n",
       "..               ...                ...   \n",
       "917  xxxxxxxxxxx_917  xxxxxxxxxxxxx_917   \n",
       "918  xxxxxxxxxxx_918  xxxxxxxxxxxxx_918   \n",
       "919  xxxxxxxxxxx_919  xxxxxxxxxxxxx_919   \n",
       "920  xxxxxxxxxxx_920  xxxxxxxxxxxxx_920   \n",
       "921  xxxxxxxxxxx_921  xxxxxxxxxxxxx_921   \n",
       "\n",
       "                                                answer  \n",
       "0    In the image, there are several cars, traffic ...  \n",
       "1    In the image, the cars are black, the traffic ...  \n",
       "2    In the image, there are two cars, two traffic ...  \n",
       "3    The cars in the image are red, the traffic lig...  \n",
       "4    In the image, there are several cars, traffic ...  \n",
       "..                                                 ...  \n",
       "917  The cars in the image are black, the traffic l...  \n",
       "918  In the image, there are no cars, traffic light...  \n",
       "919  The cars in the image are white, the traffic l...  \n",
       "920  In the image, there are no cars, traffic light...  \n",
       "921  The cars in the image are white, the traffic l...  \n",
       "\n",
       "[922 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "def get_answer(img_path, question):\n",
    "    file_pth = os.path.join(my_image_path,img_path)\n",
    "\n",
    "    response = chat(question, file_pth)\n",
    "\n",
    "    return response\n",
    "\n",
    "def str2list(input_string):\n",
    "    # Remove the brackets and split by newline character\n",
    "    list_elements = input_string.strip(\"[]\").split('\\n')\n",
    "\n",
    "    # Remove any extra spaces and quotes\n",
    "    cleaned_list = [element.strip(\" '\") for element in list_elements]\n",
    "    return cleaned_list\n",
    "\n",
    "val = pd.read_csv(my_label_path)\n",
    "val[\"images\"] = val[\"images\"].map(str2list)\n",
    "predictions = pd.DataFrame(columns=[\"question_id\", \"segment_id\", \"answer\"])\n",
    "\n",
    "for index, row in tqdm(val.iterrows(), total=val.shape[0]):\n",
    "    question_id = row['question_id']\n",
    "    segment_id = row['segment_id']\n",
    "    images = row['images']\n",
    "    question = row['question']\n",
    "    answer = row['answer']\n",
    "    # only use the first frame\n",
    "    asw = get_answer(images[0], question)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    # Create a DataFrame for the current row\n",
    "    new_row = pd.DataFrame({\n",
    "        \"question_id\": [question_id],\n",
    "        \"segment_id\": [segment_id],\n",
    "        # \"question\": [question],\n",
    "        \"answer\": [asw]\n",
    "    })\n",
    "\n",
    "    # Append the new row to the predictions DataFrame using pd.concat\n",
    "    predictions = pd.concat([predictions, new_row], ignore_index=True)\n",
    "    # break\n",
    "predictions.to_csv(my_label_path.replace(qton, qton+\"_llava_predict\"))\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
